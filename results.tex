\section{Results}

In this section, we summarise the results of our assessment.

\subsection{Distinctiveness}

%\begin{figure*}[t]
%\centerline{% 
%		\includegraphics[width=0.98\linewidth]{imgs/distinctivenessTP.pdf}}
%    \vspace{-2mm} 
%	\caption{Examples taken from the dataset showing the ratio of true positives and ambiguous true positives. The lighter color bars show the number of true positives that will actually pass the second best result test.}
%	\label{fig:distinctiveness}
%\end{figure*}

The first aspect was to assess the distinctiveness. Table~\ref{table:tp_ratio} shows the average number of key-points extracted, descriptors belonging to the object to track and the ratio of true positives (TP), false positives (FP) and true positives that pass the second best match ratio check (TTP). 

\begin{table}[!h]
\caption{Average number of feature extracted, object features, true positives and false positives. Every row is normalized by its maximum value.}
\vspace{-2mm} 
\centerline{% 
		\includegraphics[width=0.98\linewidth]{tables/descriptivness_ratio.pdf}}
    \vspace{-2mm} 
	\label{table:tp_ratio}
\end{table}

It is interesting to notice that BRISK, ORB and SIFT extract a higher number of feature descriptors in general. In particular, BRISK and ORB have a higher number of key-points extracted within the area of the object. However, looking at the average amount of true positives, it can be seen that the best performing descriptors are AKAZE and the implementation of SIFT on the GPU. This is a first indicator of the quality of the descriptors extracted. Moreover, it can be noticed that the true positives are also more distinctive in the case of AKAZE and SIFT since the number of TTP is higher.

\begin{table*}[t]
\caption{Tracking results with low, medium and high accuracy requirements. The high number of key points extracted by ORB or BRISK compensate their weak descriptors. This comes with a cost in performance.} 
\centerline{%
		\includegraphics[width=\linewidth]{tables/tracking_precision.pdf}}
		\vspace{8mm}
	\label{table:taccuracy}
\end{table*}


\subsection{Tracking accuracy}

As explained in the previous section, we evaluated the performance of the feature descriptors by running our tracker and calculating the overlap measure for low, medium and high accuracy requirements. 
\begin{figure}[!h]
	\vspace{2mm}
\centerline{%
	\subfigure{\includegraphics[width=0.48\linewidth]{imgs/results/ex5.png}}
	\subfigure{\includegraphics[width=0.48\linewidth]{imgs/results/ex6.png}}}
\caption{Examples showing the behaviour of the feature descriptors upon occlusion. Upon recovery from track loss more descriptive descriptors allow the tracker to recover faster.}
\vspace{-3mm}
\label{fig:tracking_results}
\end{figure}

Table~\ref{table:taccuracy} summarizes tracking results on all the video sequences included in the dataset.  Our experiments show that AKAZE, BRISK, ORB and SIFT have comparable results. It is interesting to note that BRISK and ORB compensate their weak distinctiveness with a higher amount of weak descriptors extracted. A high number of feature points proved to be effective in tracking in the video sequences where the object suffers drastic scale changes and full occlusion, making the recovery after track loss faster, see Fig.~\ref{fig:tracking_results}. We also noticed that AKAZE, more than SIFT, suffers the change in scale. 

\subsection{Tracking performance}

The dataset used for benchmarking includes video sequences of various resolution. Fig.~\ref{fig:speed} shows the average performance of each feature descriptor on the resolutions having the highest number of sequences. 

\begin{figure}[!htb]
	%\vspace{-2mm}
	\includegraphics[width=0.95\linewidth]{imgs/tracker_fps_std.pdf}
\vspace{-2.5mm}	
\caption{Average time spent on tracking the object in a single frame: important factors are the resolution and the number of feature descriptors extracted. The variance of the results is a good indication of how much the number of feature descriptors influences the performance. It can be seen that the implementations have a lower variation due to the high level of parallelism. }
\label{fig:speed}
\end{figure}

The two most important factors that influence performance are resolution and number of key points extracted. The former influences particularly the detection step when the scale space of descriptors is computed and key-points are detected. The latter influences more the compute step when feature descriptors are calculated and the matching step. The average performance of each separate step can be seen in Fig.~\ref{fig:speed_b}. One interesting aspect to notice is the variance of the performance in Fig.~\ref{fig:speed}: BRISK, ORB and SIFT have the higher variance while CUDA SIFT and CUDA AKAZE have lower variance. This is also a good indicator of the level of parallelism of the implementation of the descriptor.  

%We evaluate the performance of each feature descriptor in three different steps: detection, computation and matching. Fig.~\ref{fig:speed} shows the overall results on the dataset. It is interesting to notice that despite AKAZE exploits multiple core on the CPU, its detection part is expensive due to the non-linear filtering. Brisk and ORB are faster but then the matching step is more expensive given the higher number of features extracted. Please note that this numbers are only informative. We think that it is not fair to compare multi-threaded implementations (e.g AKAZE) with single threaded (SIFT) or GPU implementation (SIFT).

\begin{figure}[!htb]
	%\vspace{-2mm}
	\includegraphics[width=0.95\linewidth]{imgs/performances.pdf}
\vspace{-2.5mm}	
\caption{Performance of the compute, detect and match steps of each feature descriptor.}
\label{fig:speed_b}
\end{figure}

%\begin{table}
%\caption{Average time spent on a single frame by the tracker.}
	%\vspace{-2mm}
%	\includegraphics[width=0.95\linewidth]{tables/resolution_times.pdf}
%\vspace{-2.5mm}	
%\label{fig:fps}
%\end{table}

\subsection{Discussion}

Most of the feature descriptors proved to be effective for tracking purposes showing a good precision and performance. This is positive since it makes these suitable for real-time applications. Despite being assessed as somewhat weak in terms of distinctiveness, ORB and BRISK have been proven to be good for real time frameworks. 
However, the trade-off between the distinctiveness and accuracy is not easy to define.
AKAZE and SIFT have been proven to be more distinctive as descriptors but only their implementations of the GPU allow real time performances. 

\todo[inline]{this needs to be rewritten}

Most of the video sequence present many challenges: scale or affine transformations, appearance changes and blurring as a consequence of fast camera or object movements. AKAZE and SIFT have proven to be more effective on the sequences with small scale changes and low movements between frames. AKAZE in particular seems to be sensitive to scale changes. Moreover, we noticed that the matching rate of all features drop consistently upon fast movements of the camera. The motion blur influences negatively the quality of the feature extracted. However, tt seems that weaker descriptors are able to cope better with such problems presenting a higher number of feature descriptors that may find a potential match in the current image. It will be interesting to evaluate the performance of the feature descriptors generating affine descriptors using artificial transformations of the object as propose by Morel \cite{morel2009}.

Despite the computation of a non linear scale space is more demanding that Gaussian filtering, we noticed that the extraction and matching steps of AKAZE compensates in terms of performance due to the binary descriptor.

\todo[inline]{end part to review}

\begin{figure}[!htb]
	\vspace{2mm}
\centerline{%
	\subfigure[scale]{\includegraphics[width=0.33\linewidth]{imgs/limitations/scale.png}\label{fig:tra}}
	\subfigure[light]{\includegraphics[width=0.33\linewidth]{imgs/limitations/light.png}\label{fig:trb}}
	\subfigure[multi-instance]{\includegraphics[width=0.33\linewidth]{imgs/limitations/basket.png}\label{fig:trc}}}
	\vspace{-2mm}
\caption{Examples showing the main problems that feature descriptors cannot address. }
\label{fig:tracking_results_scale}
\end{figure} 


There are still some issue that need to be addressed in relation to achieving a robust tracking system. First, even if many descriptors are invariant to scale, we noticed that this does
not hold for drastic scale changes like in Fig.~\ref{fig:tra}. Second, feature descriptors are sensitive to light conditions, see Fig.~\ref{fig:trb}. This is particularly relevant for robotics applications since the interaction of a robotic platform with a target object may occlude the light source. Third, the common matching approach to detect an object or compute the transformation between images \cite{mikolajczyk05} does not work in the presence of multiple targets with similar appearance. This is the case shown in Fig.\ref{fig:trc} where more players have the same outfit.









